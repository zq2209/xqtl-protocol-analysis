{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d44b902",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Reference data standardization - Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-spice",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Aims:\n",
    "Through this protocol, try to understand the first step of the detection and analysis of molecular QTLs (xQTLs). This protocol mainly focus on data downloading, indexing, and processing, prepare for futher use. \n",
    "## To do:\n",
    "To understand as much as possible of this protocol, followings will be done as running through this protocal:\n",
    "* Read the Chapter 8 of the book listed in the introduction md. \n",
    "* Run all codes listed below to get a sense of what is going on.\n",
    "* Write up errors and issues happened during the run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-sucking",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Overview\n",
    "This module provides reference data download, indexing and preprocessing (if necessary), in preparation for use throughout the pipeline.\n",
    "\n",
    "Following output reference files will be used for RNA-seq expression and splicing quantification:\n",
    "\n",
    "1. `GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.{dict,fasta,fasta.fai}`\n",
    "2. `Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.ERCC.gtf` for stranded protocol, and `Homo_sapiens.GRCh38.103.chr.reformatted.gene.ERCC.gtf` for unstranded protocol.\n",
    "3. Everything under `STAR_Index` folder\n",
    "4. Everything under `RSEM_Index` folder\n",
    "5. Optionally, for quality control, `gtf_ref.flat`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-hearing",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Workflows\n",
    "\n",
    "Workflows implemented include:\n",
    "* Convert transcript feature file gff3 to gtf\n",
    "    - Input: an uncompressed gff3 file.(i.e. can be view via cat)\n",
    "\n",
    "* Collapse transcript features into genes\n",
    "    - Input: a gtf file.\n",
    "\n",
    "* Generate STAR index based on gtf and reference fasta\n",
    "    - Input: a gtf file and an acompanying fasta file.\n",
    "\n",
    "* Generate RSEM index based on gtf and reference fasta\n",
    "    - Input: a gtf file and an acompanying fasta file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-juvenile",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Details\n",
    "### To download reference data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-prevention",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb download_hg_reference --cwd reference_data\n",
    "sos run pipeline/reference_data.ipynb download_gene_annotation --cwd reference_data\n",
    "sos run pipeline/reference_data.ipynb download_ercc_reference --cwd reference_data\n",
    "sos run pipeline/reference_data.ipynb download_dbsnp --cwd reference_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-boston",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "This chunk only contains part of the path of files. It will generate error, fail to locate. To solve this, need to contain relative or absolute path of the files to lei it run. Instead, I will use codes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718d3a2",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run xqtl-pipeline/pipeline/reference_data.ipynb download_hg_reference --cwd reference_data\n",
    "sos run xqtl-pipeline/pipeline/reference_data.ipynb download_gene_annotation --cwd reference_data\n",
    "sos run xqtl-pipeline/pipeline/reference_data.ipynb download_ercc_reference --cwd reference_data\n",
    "sos run xqtl-pipeline/pipeline/reference_data.ipynb download_dbsnp --cwd reference_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4c2c68",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "This will generate a folder called reference_data in current dictionary. If want to store the data in different place, change `--cwd reference_data` to `--cwd /path-to-store/reference_data`. When getting error `like no enough space`, try to use external hard drive to store data. Remember to aovid space in the path!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-range",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### To format reference data: \n",
    "List codes for docker and sigularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-perry",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run reference_data.ipynb hg_reference \\\n",
    "    --cwd reference_data \\\n",
    "    --ercc-reference reference_data/ERCC92.fa \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.fa \\\n",
    "    --container container/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a98ce4",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "This code using sigularity to format the data. Using docker is also a way to generate same result. To use docker, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25363b50",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run xqtl-pipeline/reference_data.ipynb hg_reference \\\n",
    "    --cwd reference_data \\\n",
    "    --ercc-reference reference_data/ERCC92.fa \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.fa \\\n",
    "    --container gaow/rna_quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3040f5",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "If reference data is in a different dictionary, remember to add path, `path-to-store/reference_data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-rover",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb hg_gtf \\\n",
    "    --cwd reference_data \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.gtf \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy.fasta \\\n",
    "    --container containers/rna_quantification.sif --stranded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a311172",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run xqtl-pipeline/pipeline/reference_data.ipynb hg_gtf \\\n",
    "    --cwd reference_data \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.gtf \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy.fasta \\\n",
    "    --container gaow/rna_quantification --stranded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc26e74",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Do the same changes as above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaba9fa",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Here might result a error like `script killed by docker, probably because of RAM`. This is the memory issue of computer. It doesn't have enough memory to run, mostly happened for computers only have 8GB memory. To solve this, creating a virtual machine is a good way. Detailes refer to `Guidlines for setting virtual machine and connecting to personal computer`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-murray",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### To format gene feature data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-special",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb gene_annotation \\\n",
    "    --cwd reference_data \\\n",
    "    --ercc-gtf reference_data/ERCC92.gtf \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.gtf \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy.fasta \\\n",
    "    --container containers/rna_quantification.sif --stranded # gaow/rna_quantification --stranded if docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-civilization",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "**Notice that for un-stranded RNA-seq protocol please use switch `--no-stranded` to the command above instead of `--stranded`. More details can be found later in the document.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-equity",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### Generating STAR index without the GTF annotation file allow customize read lenght lateron in STAR alignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-shopping",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb STAR_index \\\n",
    "    --cwd reference_data \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta \\\n",
    "    --container containers/rna_quantification.sif \\ # gaow/rna_quantification --stranded if docker\n",
    "    --mem 40G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-management",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "This will generate a STAR folder in reference_data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-regression",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### To generate RSEM index with the gtf file **prior** to the gene collapsing step ( **without** the gene tag in its file name.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-insider",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb RSEM_index \\\n",
    "    --cwd reference_data \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.gtf \\\n",
    "    --container containers/rna_quantification.sif  & # gaow/rna_quantification --stranded if docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-management",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "This will generate a RSEM folder in reference_data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-carry",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "### To generate RefFlat annotation for Picard QC,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-excerpt",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb RefFlat_generation \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.gtf \n",
    "    --container containers/rna_quantification.sif & # --gaow/rna_quantification --stranded if docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-motorcycle",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "To generate the SUPPA annotation for psichomics to detect RNA alternative splicing events,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-flexibility",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb SUPPA_annotation \\\n",
    "    --hg_gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.gtf \\\n",
    "    --container containers/psichomics.sif # --gaow/psichomics --stranded if docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-tourism",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "Prepare psichomics database, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb psi_hg38_annotation \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformated.gtf \\\n",
    "    --hgrc-db reference_data/hgnc_database.txt \\\n",
    "    --container containers/psichomics.sif # --gaow/psichomics --stranded if docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765ee57",
   "metadata": {},
   "source": [
    "## Output - Screenshots are shown in Output folder\n",
    "After this protocol, a few files has been created preparing for further analysis. \n",
    "Steps include:\n",
    "* Convert transcript feature file gff3 to gtf\n",
    "* Collapse transcript features into genes\n",
    "* Generate STAR index based on gtf and reference fasta\n",
    "* Generate RSEM index based on gtf and reference fasta\n",
    "\n",
    "Outputs include\n",
    "- A gtf file.\n",
    "- A gtf file with collapesed gene model: will be used in the next protocol\n",
    "- A folder of STAR index: will be used in the next protocol\n",
    "- A folder of RSEM index: will be used in the next protocol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
