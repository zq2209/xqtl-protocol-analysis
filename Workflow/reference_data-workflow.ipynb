{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d44b902",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Reference data standardization - Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-prevention",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# The output directory for generated files.\n",
    "parameter: cwd = path(\"output\")\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"5h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# Software container option\n",
    "parameter: container = \"\"\n",
    "cwd = path(f'{cwd:a}')\n",
    "from sos.utils import expand_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a663cba",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9718d3a2",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[download_hg_reference]\n",
    "output: f\"{cwd:a}/GRCh38_full_analysis_set_plus_decoy_hla.fa\"\n",
    "download: dest_dir = cwd\n",
    "    ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/GRCh38_reference_genome/GRCh38_full_analysis_set_plus_decoy_hla.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-perry",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[download_gene_annotation]\n",
    "output: f\"{cwd:a}/Homo_sapiens.GRCh38.103.chr.gtf\"\n",
    "download: dest_dir = cwd, decompress=True\n",
    "    http://ftp.ensembl.org/pub/release-103/gtf/homo_sapiens/Homo_sapiens.GRCh38.103.chr.gtf.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25363b50",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[download_ercc_reference]\n",
    "output: f\"{cwd:a}/ERCC92.gtf\", f\"{cwd:a}/ERCC92.fa\"\n",
    "download: dest_dir = cwd, decompress=True\n",
    "    https://tools.thermofisher.com/content/sfs/manuals/ERCC92.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-rover",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[download_dbsnp]\n",
    "output: f\"{cwd:a}/00-All.vcf.gz\", f\"{cwd:a}/00-All.vcf.gz.tbi\"\n",
    "download: dest_dir = cwd\n",
    "    ftp://ftp.ncbi.nlm.nih.gov/snp/organisms/human_9606/VCF/00-All.vcf.gz\n",
    "    ftp://ftp.ncbi.nlm.nih.gov/snp/organisms/human_9606/VCF/00-All.vcf.gz.tbi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e9f39",
   "metadata": {},
   "source": [
    "## GFF3 to GTF formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a311172",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[gff3_to_gtf]\n",
    "parameter: gff3_file = path\n",
    "input: gff3_file\n",
    "output: f'{cwd}/{_input:bn}.gtf'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "        gffread ${_input} -T -o ${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed67f535",
   "metadata": {},
   "source": [
    "## HG reference file preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-special",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[hg_reference_1 (HLA ALT Decoy removal)]\n",
    "# Path to HG reference file\n",
    "parameter: hg_reference = path\n",
    "input: hg_reference\n",
    "output:  f'{cwd}/{_input:bn}.noALT_noHLA_noDecoy.fasta'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    with open('${_input}', 'r') as fasta:\n",
    "        contigs = fasta.read()\n",
    "        contigs = contigs.split('>')\n",
    "        contig_ids = [i.split(' ', 1)[0] for i in contigs]\n",
    "\n",
    "        # exclude ALT, HLA and decoy contigs\n",
    "        filtered_fasta = '>'.join([c for i,c in zip(contig_ids, contigs)\n",
    "        if not (i[-4:]=='_alt' or i[:3]=='HLA' or i[-6:]=='_decoy')])\n",
    "    \n",
    "    with open('${_output}', 'w') as fasta:\n",
    "        fasta.write(filtered_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-shopping",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[hg_reference_2 (merge with ERCC reference)]\n",
    "parameter: ercc_reference = path\n",
    "output: f'{cwd}/{_input:bn}_ERCC.fasta'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    sed 's/ERCC-/ERCC_/g' ${ercc_reference} > ${ercc_reference:n}.patched.fa\n",
    "    cat ${_input} ${ercc_reference:n}.patched.fa > ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-insider",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[hg_reference_3 (index the fasta file)]\n",
    "output: f'{cwd}/{_input:bn}.dict'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    samtools faidx ${_input}\n",
    "    java -jar /opt/picard-tools/picard.jar \\\n",
    "        CreateSequenceDictionary \\\n",
    "        R=${_input} \\\n",
    "        O=${_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3929cece",
   "metadata": {},
   "source": [
    "## Transcript and gene model reference processingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-excerpt",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[hg_gtf_1 (add chr prefix to gtf file)]\n",
    "parameter: hg_reference = path\n",
    "parameter: hg_gtf = path\n",
    "input: hg_reference, hg_gtf\n",
    "output: f'{cwd}/{_input[1]:bn}.reformatted.gtf'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    library(\"readr\")\n",
    "    library(\"stringr\")\n",
    "    library(\"dplyr\")\n",
    "    options(scipen = 999)\n",
    "    con <- file(\"${_input[0]}\",\"r\")\n",
    "    fasta <- readLines(con,n=1)\n",
    "    close(con)\n",
    "    gtf = read_delim(\"${_input[1]}\", \"\\t\",  col_names  = F, comment = \"#\", col_types=\"ccccccccc\")\n",
    "    if(!str_detect(fasta,\">chr\")) {\n",
    "        gtf_mod = gtf%>%mutate(X1 = str_remove_all(X1,\"chr\"))\n",
    "    } else if (!any(str_detect(gtf$X1[1],\"chr\"))) {\n",
    "        gtf_mod = gtf%>%mutate(X1 = paste0(\"chr\",X1))\n",
    "    } else (gtf_mod = gtf)\n",
    "    if(any(str_detect(gtf_mod$X9, \"transcript_biotype\"))) {\n",
    "      gtf_mod = gtf_mod%>%mutate(X9 = str_replace_all(X9,\"transcript_biotype\",\"transcript_type\"))\n",
    "    }\n",
    "    gtf_mod%>%write.table(\"${_output}\",sep = \"\\t\",quote = FALSE,col.names = F,row.names = F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-flexibility",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[hg_gtf_2 (collapsed gene model)]\n",
    "parameter: stranded = bool\n",
    "output: f'{_input:n}{\".collapse_only\" if stranded else \"\"}.gene.gtf'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    collapse_annotation.py ${\"--collapse_only\" if stranded else \"\"} ${_input} ${_output}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[ercc_gtf (Preprocess ERCC gtf file)]\n",
    "parameter: ercc_gtf = path\n",
    "input: ercc_gtf\n",
    "output: f'{cwd}/{_input:bn}.genes.patched.gtf'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "python: expand = \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout', container = container\n",
    "    with open('${_input}') as exon_gtf, open('${_output}', 'w') as gene_gtf:\n",
    "        for line in exon_gtf:\n",
    "            f = line.strip().split('\\t')\n",
    "            f[0] = f[0].replace('-','_')  # required for RNA-SeQC/GATK (no '-' in contig name)\n",
    "        \n",
    "            attr = f[8]\n",
    "            if attr[-1]==';':\n",
    "                attr = attr[:-1]\n",
    "            attr = dict([i.split(' ') for i in attr.replace('\"','').split('; ')])\n",
    "            # add gene_name, gene_type\n",
    "            attr['gene_name'] = attr['gene_id']\n",
    "            attr['gene_type'] = 'ercc_control'\n",
    "            attr['gene_status'] = 'KNOWN'\n",
    "            attr['level'] = 2\n",
    "            for k in ['id', 'type', 'name', 'status']:\n",
    "                attr['transcript_'+k] = attr['gene_'+k]\n",
    "        \n",
    "            attr_str = []\n",
    "            for k in ['gene_id', 'transcript_id', 'gene_type', 'gene_status', 'gene_name',\n",
    "                'transcript_type', 'transcript_status', 'transcript_name']:\n",
    "                attr_str.append('{0:s} \"{1:s}\";'.format(k, attr[k]))\n",
    "            attr_str.append('{0:s} {1:d};'.format('level', attr['level']))\n",
    "            f[8] = ' '.join(attr_str)\n",
    "        \n",
    "            # write gene, transcript, exon\n",
    "            gene_gtf.write('\\t'.join(f[:2]+['gene']+f[3:])+'\\n')\n",
    "            gene_gtf.write('\\t'.join(f[:2]+['transcript']+f[3:])+'\\n')\n",
    "            f[8] = ' '.join(attr_str[:2])\n",
    "            gene_gtf.write('\\t'.join(f[:2]+['exon']+f[3:])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[gene_annotation]\n",
    "input: output_from(\"hg_gtf_1\"), output_from(\"hg_gtf_2\"), output_from(\"ercc_gtf\")\n",
    "output: f'{cwd}/{_input[0]:bn}.ERCC.gtf', f'{cwd}/{_input[1]:bn}.ERCC.gtf'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "bash: expand = \"${ }\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container\n",
    "    cat ${_input[0]} ${_input[2]} > ${_output[0]}\n",
    "    cat ${_input[1]} ${_input[2]} > ${_output[1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5247b1",
   "metadata": {},
   "source": [
    "## Generating index file for STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[STAR_index]\n",
    "parameter: hg_reference = path\n",
    "# Specifies the length of the genomic sequence around the annotated junction to be used in constructing the splice junctions database. Ideally, this length should be equal to the ReadLength-1, where ReadLength is the length of the reads.\n",
    "# Default choice follows from TOPMed pipeline recommendation.\n",
    "if expand_size(mem) < expand_size('40G'):\n",
    "    print(\"Insufficent memory for STAR, changing to 40G\")\n",
    "    star_mem = '40G'\n",
    "else:\n",
    "    star_mem = mem\n",
    "input: hg_reference\n",
    "output: f\"{cwd}/STAR_Index/chrName.txt\", \n",
    "        f\"{cwd}/STAR_Index/SAindex\", f\"{cwd}/STAR_Index/SA\", f\"{cwd}/STAR_Index/genomeParameters.txt\", \n",
    "        f\"{cwd}/STAR_Index/chrStart.txt\",\n",
    "        f\"{cwd}/STAR_Index/chrLength.txt\", \n",
    "        f\"{cwd}/STAR_Index/Genome\", f\"{cwd}/STAR_Index/chrNameLength.txt\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output[0]:bd}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[1]:n}.stderr', stdout = f'{_output[1]:n}.stdout'\n",
    "    STAR --runMode genomeGenerate \\\n",
    "         --genomeDir ${_output[0]:d} \\\n",
    "         --genomeFastaFiles ${_input[0]} \\\n",
    "         --runThreadN ${numThreads}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6543e1f",
   "metadata": {},
   "source": [
    "## Generating index file for RSEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[RSEM_index]\n",
    "parameter: hg_gtf = path\n",
    "parameter: hg_reference = path\n",
    "input: hg_reference, hg_gtf\n",
    "output: f\"{cwd}/RSEM_Index/rsem_reference.n2g.idx.fa\", f\"{cwd}/RSEM_Index/rsem_reference.grp\", \n",
    "        f\"{cwd}/RSEM_Index/rsem_reference.idx.fa\", f\"{cwd}/RSEM_Index/rsem_reference.ti\", \n",
    "        f\"{cwd}/RSEM_Index/rsem_reference.chrlist\", f\"{cwd}/RSEM_Index/rsem_reference.seq\", \n",
    "        f\"{cwd}/RSEM_Index/rsem_reference.transcripts.fa\"\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output[0]:bd}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output[1]:n}.stderr', stdout = f'{_output[1]:n}.stdout'\n",
    "    rsem-prepare-reference \\\n",
    "            ${_input[0]} \\\n",
    "            ${_output[1]:n} \\\n",
    "            --gtf ${_input[1]} \\\n",
    "            --num-threads ${numThreads}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1adb8",
   "metadata": {},
   "source": [
    "## Generation of RefFlat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[RefFlat_generation]\n",
    "parameter: hg_gtf = path\n",
    "input: hg_gtf\n",
    "output: f'{_input:n}.ref.flat'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output[0]:bd}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    gtfToGenePred ${_input}  ${_output}.tmp -genePredExt -geneNameAsName2\n",
    "    awk -F'\\t' -v OFS=\"\\t\" '{$1=$12 OFS $1;}7' ${_output}.tmp | cut -f 1-11 > ${_output}\n",
    "    rm ${_output}.tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328588ea",
   "metadata": {},
   "source": [
    "## Generation of SUPPA annotation for psichomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[SUPPA_annotation_1]\n",
    "parameter: hg_gtf = path\n",
    "input: hg_gtf\n",
    "output: f'{cwd}/hg38.{_input:bn}_SE_strict.ioe' # The stderr file must not shared the same start with the output file\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "bash: container=container, expand= \"${ }\", stderr = f'{cwd}/{_input:bn}.stderr', stdout = f'{cwd}/{_input:bn}.stdout'\n",
    "    python /opt/SUPPA/suppa.py generateEvents -i ${_input} -o ${cwd}/hg38.${_input:bn} -f ioe -e SE SS MX RI FL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[SUPPA_annotation_2]\n",
    "parameter: hg_gtf = path\n",
    "output: f'{cwd}/{hg_gtf:bn}.SUPPA_annotation.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "R: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    library(\"psichomics\")\n",
    "    suppa <- parseSuppaAnnotation(\"${_input:d}\", genome=\"hg38\") \n",
    "    annot <- prepareAnnotationFromEvents(suppa)\n",
    "    saveRDS(annot, file=${_output:r})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90a1241",
   "metadata": {},
   "source": [
    "## Generate psichomics Hg38 splicing annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-mother",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "[psi_hg38_annotation]\n",
    "parameter: hg_gtf = path\n",
    "# FIXME: Please document what this file is and where do we get it @xuanhe.\n",
    "parameter: hgrc_db = path\n",
    "input: hg_gtf, hgrc_db\n",
    "output: f'{cwd}/psichomics_hg38_annotation.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, tags = f'{step_name}_{_output:bn}'\n",
    "R: container=container, expand= \"${ }\", stderr = f'{_output}.stderr', stdout = f'{_output}.stdout'\n",
    "    library(\"psichomics\")\n",
    "    library(\"purrr\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"data.table\")\n",
    "  \n",
    "    # load psicomics default annotation, option of hg38 from listSplicingAnnotations()\n",
    "    annotation <- loadAnnotation(\"AH63657\")\n",
    "\n",
    "    \n",
    "    # reduce the demension of annotation file\n",
    "    annotation <- \n",
    "      map(annotation, ~.x%>%\n",
    "                       tidyr::unnest(cols = `Gene`))\n",
    "  \n",
    "    # Create empty colomns for each event for easier mapping\n",
    "    annotation[[\"Tandem UTR\"]][[\"SUPPA.Event.ID\"]] <- NA\n",
    "    annotation[[\"Tandem UTR\"]][[\"VAST-TOOLS.Event.ID\"]] <- NA\n",
    "    annotation[[\"Alternative first exon\"]][[\"VAST-TOOLS.Event.ID\"]] <- NA\n",
    "    annotation[[\"Alternative last exon\"]][[\"VAST-TOOLS.Event.ID\"]] <- NA\n",
    "    annotation[[\"Mutually exclusive exon\"]][[\"VAST-TOOLS.Event.ID\"]] <- NA\n",
    "  \n",
    "    # extract Ensembl ID substring from original SUPPA.ID and VASTTOOL.ID\n",
    "    annotation <- \n",
    "      map(annotation, ~.x%>%\n",
    "                       mutate(ENSG.SUPPA = substr(`SUPPA.Event.ID`, 1, 15))%>%\n",
    "                       mutate(ENSG.VAST = substr(`VAST-TOOLS.Event.ID`, 1, 15)))\n",
    "  \n",
    "    # Load gtf file\n",
    "    gtf_sample <- read.table('${_input[0]}',header = FALSE, sep = '\\t')\n",
    "  \n",
    "    # from the gtf file, seperate gene names and corresponding Ensembl ID\n",
    "    gtf_sample <- separate(gtf_sample, V9, sep = \";\",into = c(\"gene_id\", \"transcript_id\", \"exon_number\", \"gene_name\"))\n",
    "    gtf_sample <- separate(gtf_sample, gene_id, sep = \" \",into = c(\"gene_id\", \"gene_id_val\"))\n",
    "    gtf_sample <- separate(gtf_sample, gene_name, sep = \"e \",into = c(\"gene_name\", \"gene_name_val\"))\n",
    "  \n",
    "    gtf_name_id_match <- gtf_sample[,c(\"gene_id_val\",\"gene_name_val\")]\n",
    "    gtf_name_id_match <- gtf_name_id_match[!duplicated(gtf_name_id_match), ]\n",
    "  \n",
    "    # For any matched approved id in the psi hg38 annotation and gtf file, record the corresponding Ensembl ID\n",
    "    annotation <-\n",
    "      map(annotation, ~.x%>%\n",
    "                       mutate(`ENSG.GTF` = gtf_name_id_match$gene_id_val[match(`Gene`, gtf_name_id_match$gene_name_val)]))\n",
    "  \n",
    "    # load hgnc database\n",
    "    hgnc_db <- fread('${_input[1]}', fill = TRUE, header = TRUE, sep = '\\t', quote=\"\")\n",
    "  \n",
    "    # Combine the `Ensembl.ID.supplied.by.Ensembl.` and `Ensembl.gene.ID` column, if there are any conflict use the former\n",
    "    # For conflict ones (15 total) both the former and latter records are poiting to the same gene name in Ensembl website so the order should not matter\n",
    "    hgnc_db <- hgnc_db %>%\n",
    "    mutate(ENSG.ID = ifelse(`Ensembl ID(supplied by Ensembl)` == \"\", `Ensembl gene ID`, `Ensembl ID(supplied by Ensembl)`))\n",
    "  \n",
    "    # Create a one to one reference list for approved names, previous names and aliases\n",
    "    # There is no duplicate symbol and Ensembl id info for approved symbol so no need for chromosome verification\n",
    "    hgnc_name_id_match <- hgnc_db[,c(\"Approved symbol\",\"ENSG.ID\")]\n",
    "    hgnc_name_prev_check <- hgnc_db[,c(\"Previous symbols\",\"Chromosome\",\"ENSG.ID\")]\n",
    "    hgnc_name_alias_check <- hgnc_db[,c(\"Alias symbols\",\"Chromosome\",\"ENSG.ID\")]\n",
    "  \n",
    "    # Remove NAs\n",
    "    hgnc_name_prev_check <- hgnc_name_prev_check[hgnc_name_prev_check$ENSG.ID != \"\",]\n",
    "    hgnc_name_alias_check <- hgnc_name_alias_check[hgnc_name_alias_check$ENSG.ID != \"\",]\n",
    "\n",
    "    hgnc_name_prev_check <- hgnc_name_prev_check[hgnc_name_prev_check$\"Previous symbols\" != \"\",] \n",
    "    hgnc_name_alias_check <- hgnc_name_alias_check[hgnc_name_alias_check$\"Alias symbols\" != \"\",]\n",
    "\n",
    "    # Seperate symbol column values from list of sybols to individual rows with one each\n",
    "    hgnc_name_prev_check <- separate_rows(hgnc_name_prev_check, \"Previous symbols\", convert = FALSE)\n",
    "    hgnc_name_alias_check <- separate_rows(hgnc_name_alias_check, \"Alias symbols\", convert = FALSE)\n",
    "  \n",
    "    # Convert chomosome info in hgnc database to number for matching with other database\n",
    "    hgnc_name_prev_check <- separate(hgnc_name_prev_check, \"Chromosome\", sep = 'p', into = \"Chrp\", remove = FALSE)\n",
    "    hgnc_name_prev_check <- separate(hgnc_name_prev_check, \"Chromosome\", sep = 'q', into = \"Chrq\", remove = FALSE)\n",
    "    hgnc_name_prev_check <- hgnc_name_prev_check%>%\n",
    "                                mutate(Chr = ifelse(nchar(hgnc_name_prev_check$Chrp) <= 2, Chrp, Chrq))\n",
    "    \n",
    "    hgnc_name_alias_check <- separate(hgnc_name_alias_check, \"Chromosome\", sep = 'p', into = \"Chrp\", remove = FALSE)\n",
    "    hgnc_name_alias_check <- separate(hgnc_name_alias_check, \"Chromosome\", sep = 'q', into = \"Chrq\", remove = FALSE)\n",
    "    hgnc_name_alias_check <- hgnc_name_alias_check%>%\n",
    "                                mutate(Chr = ifelse(nchar(hgnc_name_alias_check$Chrp) <= 2, Chrp, Chrq))\n",
    "  \n",
    "    # For any matched approved id in the psi hg38 annotation and hgnc database, record the corresponding Ensembl ID\n",
    "    annotation <-\n",
    "      map(annotation, ~.x%>%\n",
    "                       mutate(`ENSG.HGNC` = hgnc_name_id_match$`ENSG.ID`[match(`Gene`, hgnc_name_id_match$\"Approved symbol\")]))\n",
    "  \n",
    "    # Drop hypothetical genes\n",
    "    annotation<-\n",
    "      map(annotation, ~.x%>%\n",
    "            subset(`Gene` != 'Hypothetical'))\n",
    "  \n",
    "    # IN remaining NAs, for any matched alias/previous names and chromosome in the psi hg38 annotation and hgnc database, record the corresponding Ensembl ID\n",
    "    annotation <-\n",
    "      map(annotation, ~.x%>%\n",
    "                      mutate(ENSG.HGNC = ifelse(is.na(`ENSG.HGNC`) | `ENSG.HGNC` == \"\",\n",
    "                                                hgnc_name_alias_check$`ENSG.ID`[match(`Gene`, hgnc_name_alias_check$\"Alias symbols\") & match(`Chromosome`, hgnc_name_alias_check$Chr)],\n",
    "                                                `ENSG.HGNC`))%>%\n",
    "                      mutate(ENSG.HGNC = ifelse(is.na(`ENSG.HGNC`) | `ENSG.HGNC` == \"\",\n",
    "                                                hgnc_name_prev_check$`ENSG.ID`[match(`Gene`, hgnc_name_prev_check$\"Previous symbols\") & match(`Chromosome`, hgnc_name_prev_check$Chr)],\n",
    "                                                `ENSG.HGNC`)))\n",
    "  \n",
    "    # Build the final Ensembl id column base on the gtf file first, then for remaining NAs check the HGNC database record, SUPPA and VASTTOOL record,\n",
    "    # Drop special cases that Ensembl ID is not recorded in VASTTOOLs and SUPPA\n",
    "    # finnally in the remaining NA Ensmbl ID if the gene name in original annotation is NCBI IDs just use it\n",
    "    annotation <-\n",
    "      map(annotation, ~.x%>%\n",
    "                       mutate(`ENSG.ID` = `ENSG.GTF`)%>%\n",
    "                       mutate(`ENSG.ID` = ifelse(is.na(`ENSG.ID`),\n",
    "                                               `ENSG.HGNC`,\n",
    "                                                `ENSG.ID`))%>%\n",
    "                       mutate(`ENSG.ID` = ifelse(is.na(`ENSG.ID`),\n",
    "                                               `ENSG.VAST`,\n",
    "                                                `ENSG.ID`))%>%\n",
    "                       mutate(`ENSG.ID` = ifelse(is.na(`ENSG.ID`),\n",
    "                                               `ENSG.SUPPA`,\n",
    "                                                `ENSG.ID`))%>%\n",
    "                       mutate(`ENSG.ID` = ifelse(substr(`ENSG.ID`, 1, 4) == 'ENSG',\n",
    "                                                 `ENSG.ID`,\n",
    "                                                 NA))%>%\n",
    "                       mutate(`ENSG.ID` = ifelse(is.na(`ENSG.ID`) & substr(`Gene`, 1, 3) == 'LOC',\n",
    "                                               `Gene`,\n",
    "                                                `ENSG.ID`)))\n",
    "\n",
    "    # Use the Ensembl IDs to replace gene names, drop remaining NAs\n",
    "    annotation <-\n",
    "    map(annotation, ~.x%>%\n",
    "                       mutate(`Gene` = `ENSG.ID`)%>%\n",
    "            drop_na(`Gene`)\n",
    "          )\n",
    "\n",
    "    # save modified annotation\n",
    "    saveRDS(annotation, file = \"${_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     "shell"
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
